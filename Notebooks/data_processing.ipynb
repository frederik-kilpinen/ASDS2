{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/frederik-kilpinen/ASDS2/blob/main/Notebooks/data_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Wrangling and Mergin\n",
    "2. Text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wranling and Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "K5jNeH3d9cqY"
   },
   "outputs": [],
   "source": [
    "#Necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tweepy\n",
    "from datetime import date\n",
    "import pickle \n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8_kMAvdu9cqb",
    "outputId": "b54884f6-b012-498c-d30c-c5e4f42f0be7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15918, 37)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MP info dataset\n",
    "mp_df = pd.read_csv(\"data/full_member_info.csv\")\n",
    "\n",
    "#Original shape of the data\n",
    "mp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nAK3IMzd9cqc",
    "outputId": "061ce6d8-ec6e-4b8d-bbfc-fe8c37cbbf70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335975, 12)\n"
     ]
    }
   ],
   "source": [
    "# Twitter dataset\n",
    "tweets = pd.read_csv(\"data/mp_tweets\", index_col=0, low_memory=False)\n",
    "\n",
    "#Original shape of the data\n",
    "print(tweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LiXo-A0o9cqd"
   },
   "outputs": [],
   "source": [
    "class DataProcessing:\n",
    "\n",
    "    def clean_tweet_data(self, tweet_df):\n",
    "\n",
    "\n",
    "        #Drop 6 tweets that are corrupt. Because of it only being 6 tweets we drop them instead of re-running the collection from the API\n",
    "        remove_idx = [175522, 190414, 211953, 212012, 212013, 212298 ]\n",
    "        tweet_df = tweet_df.drop(tweet_df.index[remove_idx])\n",
    "\n",
    "        #Make data into date-time object, remove h-m-s from dt\n",
    "        tweet_df[\"created_at\"] = pd.to_datetime(pd.to_datetime(tweet_df[\"created_at\"]).dt.date)\n",
    "        \n",
    "        tweet_df[\"user_id\"] = tweet_df[\"user_id\"].astype(int)\n",
    "        \n",
    "        return tweet_df\n",
    "    \n",
    "    def clean_mp_data(self, mp_df):\n",
    "        \n",
    "        \n",
    "        \n",
    "        mp_df = mp_df[['p.country', 'm.name', 'p.party', 'm.uid', 'lp.official_legislative_period']]\n",
    "        mp_df = mp_df.loc[mp_df[\"p.country\"]==\"Australia\"]\n",
    "        \n",
    "        #Drop australia column\n",
    "        mp_df = mp_df.drop(columns = [\"p.country\"])\n",
    "        #Rename some columns\n",
    "        mp_df = mp_df.rename(columns = {\"m.name\":\"name\", \"p.party\":\"party\",\n",
    "                                       \"lp.official_legislative_period\":\"legislative_period\"})\n",
    "        \n",
    "        #Rename user id column for merging with members_info data\n",
    "        mp_df = mp_df.rename(columns = {\"m.uid\":\"user_id\"})\n",
    "        \n",
    "        \n",
    "        remove = r\"(^[A-Za-z]{2}\\s{1}|\\s{1}[A-Z]{2,}|^Hon\\s{1}|^Mrs\\s{1}|(Dr\\s)|,)\"\n",
    "        mp_df[\"name\"] = mp_df[\"name\"].str.replace(remove, \"\", regex = True)\n",
    "        \n",
    "        mp_df = mp_df.loc[mp_df[\"user_id\"] != \"\\\\N\"]\n",
    "        mp_df[\"user_id\"] = mp_df[\"user_id\"].astype(int)\n",
    "        \n",
    "        # Merge the Nick Xenophon Team and Centre Alliance \n",
    "        mp_df[\"party\"] = mp_df[\"party\"].apply(lambda x: \"Centre Alliance\" if x == \"Nick Xenophon Team\" else x)\n",
    "        \n",
    "        \n",
    "\n",
    "        return mp_df\n",
    "    \n",
    "    def merge_final_df(self, tweet_df, mp_df):\n",
    "        \n",
    "        \n",
    "        tweet_df = self.clean_tweet_data(tweet_df)\n",
    "        mp_df = self.clean_mp_data(mp_df)\n",
    "        \n",
    "        #Merge to final df\n",
    "        final_df = tweet_df.merge(mp_df, on = \"user_id\", how = \"left\")\n",
    "        \n",
    "        #Subset on active MPs\n",
    "        final_df = final_df.loc[((final_df[\"legislative_period\"] == \"45\") & (final_df[\"created_at\"] < \"2019-07-01\"))|\n",
    "                                ((final_df[\"legislative_period\"] == \"46\") & (final_df[\"created_at\"] > \"2019-07-01\"))]\n",
    "        \n",
    "        # FREDERIKS CHANGE: Subset tweets from 1 year before the bushfire (1. June 2018) and 1 year after the bushfire (1. May 2021)\n",
    "        final_df = final_df.loc[(final_df[\"created_at\"] >= \"2018-06-01\") & (final_df[\"created_at\"] <= \"2021-04-30\")]\n",
    "           \n",
    "        # Restetting index for final df\n",
    "        final_df = final_df.reset_index(drop = True)\n",
    "        \n",
    "        return final_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OiQmYnQI9cqe",
    "outputId": "fba3aa0e-4485-4a66-95c5-bea11b91710d"
   },
   "outputs": [],
   "source": [
    "processor = DataProcessing()\n",
    "final_df = processor.merge_final_df(tweets, mp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"final_tweet_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df[\"name\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process tweet text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170338, 15)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "#Reusing and tweaking the function for preprocessing from last week to fit specifics of this dataset.\n",
    "def preprocess(text):\n",
    "    \n",
    "    #Lowercasing words\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    #Removing '&amp' which was found to be common\n",
    "    text = re.sub(r'&amp','', text)\n",
    "    \n",
    "    #Replace other instances of \"&\" with \"and\"\n",
    "    text = re.sub(r'&','and', text)\n",
    "    \n",
    "    #Removing mentions \n",
    "    text = re.sub(r'@\\w+ ', '', text)\n",
    "    \n",
    "    #Removing 'RT' and 'via'\n",
    "    text = re.sub(r'(^rt|^via)((?:\\b\\W*@\\w+)+): ', '', text)\n",
    "    \n",
    "    #Removing punctuation\n",
    "    my_punctuation = string.punctuation.replace('#','')\n",
    "    my_punctuation = my_punctuation.replace('-','')\n",
    "    \n",
    "    text = text.translate(str.maketrans('', '', my_punctuation))\n",
    "    text = re.sub(r' - ','', text) #removing dash lines bounded by whitespace (and therefore not part of a word)\n",
    "    text = re.sub(r'[’“”—,!]','',text) #removing punctuation that is not captured by string.punctuation\n",
    "    \n",
    "    #Removing odd special characters\n",
    "    text = re.sub(r\"[┻┃━┳┓┏┛┗]\",\"\", text)\n",
    "    text = re.sub(r\"\\u202F|\\u2069|\\u200d|\\u2066\",\"\", text)\n",
    "    \n",
    "    #Removing URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    #Removing numbers\n",
    "    text = re.sub(r'[0-9]','', text)\n",
    "    \n",
    "    #Removing separators and superfluous whitespace\n",
    "    text = text.strip()\n",
    "    text = re.sub(r' +',' ',text)\n",
    "    \n",
    "    #Tokenizing\n",
    "    tokenizer = TweetTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    return tokens\n",
    "    \n",
    "\n",
    "def preprocess_lemma(tokens):\n",
    "    \n",
    "    #Running the preprocess function\n",
    "    tokens = preprocess(tokens)\n",
    "    \n",
    "    #Lemmatizing\n",
    "    tag_map = defaultdict(lambda : nltk.corpus.wordnet.NOUN)      #POS map\n",
    "    tag_map['J'] = nltk.corpus.wordnet.ADJ\n",
    "    tag_map['V'] = nltk.corpus.wordnet.VERB\n",
    "    tag_map['R'] = nltk.corpus.wordnet.ADV    \n",
    "    \n",
    "    lemmatizer = nltk.WordNetLemmatizer()             #Creating lemmatizer.\n",
    "    text_lemmatized = []                              #Empty list to save lemmatized sentence\n",
    "\n",
    "    for word, tag in nltk.pos_tag(tokens):\n",
    "        lemma = lemmatizer.lemmatize(word, tag_map[tag[0]])\n",
    "        text_lemmatized.append(lemma)\n",
    "    \n",
    "    tokens = text_lemmatized\n",
    "\n",
    "    #Removing stopwords\n",
    "    stop_words_list = nltk.corpus.stopwords.words(\"english\")\n",
    "    text = \" \".join([i for i in tokens if i not in stop_words_list])\n",
    "    \n",
    "    return text\n",
    "\n",
    "def preprocess_stem(tokens):\n",
    "    \n",
    "    #Running the preprocess function\n",
    "    tokens = preprocess(tokens)\n",
    "    \n",
    "    #Removing stopwords\n",
    "    stop_words_list = nltk.corpus.stopwords.words(\"english\")\n",
    "    tokens = [i for i in tokens if i not in stop_words_list]\n",
    "    \n",
    "    #Stemming\n",
    "    stemmer = nltk.PorterStemmer()    #Creating stemmer\n",
    "    sent_stemmed = []                 #Empty list to save stemmed sentence\n",
    "    \n",
    "    for word in tokens:\n",
    "        stem = stemmer.stem(word)     #Stemming words\n",
    "        sent_stemmed.append(stem)\n",
    "        \n",
    "    tokens = sent_stemmed\n",
    "    \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lemmatized column\n",
    "\n",
    "final_df[\"lemma_text\"] = final_df[\"full_text\"].apply(lambda x: preprocess_lemma(x))\n",
    "final_df[\"stemmed_text\"] = final_df[\"full_text\"].apply(lambda x: preprocess_stem(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the nan values with empty strings\n",
    "final_df.lemma_text = final_df.lemma_text.apply(lambda x: \"\" if str(x) == \"nan\" else x)\n",
    "final_df.stemmed_text = final_df.stemmed_text.apply(lambda x: \"\" if str(x) == \"nan\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add additional lemma and stemmed columns with only nouns proper nouns and verbs\n",
    "from textblob import TextBlob\n",
    "\n",
    "def get_bos(text):\n",
    "    blob = TextBlob(text)\n",
    "    return [ word for (word,tag) in blob.tags if tag in [\"NN\", \"NNP\", \"VD\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df[\"lemma_text_sub\"] = final_df[\"lemma_text\"].apply(lambda x: get_bos(x))\n",
    "final_df[\"stemmed_text_sub\"] = final_df[\"stemmed_text\"].apply(lambda x: get_bos(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>url</th>\n",
       "      <th>image_url</th>\n",
       "      <th>name</th>\n",
       "      <th>party</th>\n",
       "      <th>legislative_period</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemma_text_sub</th>\n",
       "      <th>stemmed_text_sub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AlanTudgeMP</td>\n",
       "      <td>185932331</td>\n",
       "      <td>1.388275e+18</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>Get the fundamentals right and lift our game. ...</td>\n",
       "      <td>18</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.theaustralian.com.au/inquirer/get-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alan Tudge</td>\n",
       "      <td>Liberal Party of Australia</td>\n",
       "      <td>46</td>\n",
       "      <td>get fundamental right lift game see thought pr...</td>\n",
       "      <td>get fundament right lift game see thought prio...</td>\n",
       "      <td>[lift, game, priority, curriculum, review]</td>\n",
       "      <td>[game, nation, curriculum, review]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AlanTudgeMP</td>\n",
       "      <td>185932331</td>\n",
       "      <td>1.388274e+18</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>RT @australian: State and federal education mi...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>['australian']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alan Tudge</td>\n",
       "      <td>Liberal Party of Australia</td>\n",
       "      <td>46</td>\n",
       "      <td>state federal education minister set oppose el...</td>\n",
       "      <td>state feder educ minist set oppos element prop...</td>\n",
       "      <td>[state, education, minister, element, school, ...</td>\n",
       "      <td>[state, feder, minist, element, school, curric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AlanTudgeMP</td>\n",
       "      <td>185932331</td>\n",
       "      <td>1.388039e+18</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>Great support for our $53m Higher Education su...</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/ITECAust/status/1387941814...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alan Tudge</td>\n",
       "      <td>Liberal Party of Australia</td>\n",
       "      <td>46</td>\n",
       "      <td>great support high education support package</td>\n",
       "      <td>great support higher educ support packag</td>\n",
       "      <td>[support, education, support, package]</td>\n",
       "      <td>[support, support, packag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AlanTudgeMP</td>\n",
       "      <td>185932331</td>\n",
       "      <td>1.388035e+18</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>RT @IndependentHEA: IHEA welcomes today’s anno...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>['IndependentHEA', 'AlanTudgeMP', 'stuartrober...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alan Tudge</td>\n",
       "      <td>Liberal Party of Australia</td>\n",
       "      <td>46</td>\n",
       "      <td>ihea welcome todays announcement unveil suite ...</td>\n",
       "      <td>ihea welcom today announc unveil suit budget m...</td>\n",
       "      <td>[welcome, announcement, suite, budget, measure...</td>\n",
       "      <td>[ihea, welcom, today, suit, budget, measur, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AlanTudgeMP</td>\n",
       "      <td>185932331</td>\n",
       "      <td>1.388031e+18</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>RT @ITECAust: The Australian — As @TimDoddEDU ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>['ITECAust', 'TimDoddEDU']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alan Tudge</td>\n",
       "      <td>Liberal Party of Australia</td>\n",
       "      <td>46</td>\n",
       "      <td>australian report iteca welcome australian gov...</td>\n",
       "      <td>australian report iteca welcom australian gove...</td>\n",
       "      <td>[report, government, support, …]</td>\n",
       "      <td>[report, iteca, welcom, support, provid, …]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   screen_name    user_id      tweet_id created_at  \\\n",
       "0  AlanTudgeMP  185932331  1.388275e+18 2021-04-30   \n",
       "1  AlanTudgeMP  185932331  1.388274e+18 2021-04-30   \n",
       "2  AlanTudgeMP  185932331  1.388039e+18 2021-04-30   \n",
       "3  AlanTudgeMP  185932331  1.388035e+18 2021-04-30   \n",
       "4  AlanTudgeMP  185932331  1.388031e+18 2021-04-30   \n",
       "\n",
       "                                           full_text favorite_count  \\\n",
       "0  Get the fundamentals right and lift our game. ...             18   \n",
       "1  RT @australian: State and federal education mi...              0   \n",
       "2  Great support for our $53m Higher Education su...             12   \n",
       "3  RT @IndependentHEA: IHEA welcomes today’s anno...              0   \n",
       "4  RT @ITECAust: The Australian — As @TimDoddEDU ...              0   \n",
       "\n",
       "   retweet_count in_reply_to_screen_name hashtags  \\\n",
       "0            7.0                     NaN       []   \n",
       "1            6.0                     NaN       []   \n",
       "2            3.0                     NaN       []   \n",
       "3            2.0                     NaN       []   \n",
       "4            1.0                     NaN       []   \n",
       "\n",
       "                                       user_mentions  \\\n",
       "0                                                 []   \n",
       "1                                     ['australian']   \n",
       "2                                                 []   \n",
       "3  ['IndependentHEA', 'AlanTudgeMP', 'stuartrober...   \n",
       "4                         ['ITECAust', 'TimDoddEDU']   \n",
       "\n",
       "                                                 url  image_url        name  \\\n",
       "0  https://www.theaustralian.com.au/inquirer/get-...        NaN  Alan Tudge   \n",
       "1                                                NaN        NaN  Alan Tudge   \n",
       "2  https://twitter.com/ITECAust/status/1387941814...        NaN  Alan Tudge   \n",
       "3                                                NaN        NaN  Alan Tudge   \n",
       "4                                                NaN        NaN  Alan Tudge   \n",
       "\n",
       "                        party legislative_period  \\\n",
       "0  Liberal Party of Australia                 46   \n",
       "1  Liberal Party of Australia                 46   \n",
       "2  Liberal Party of Australia                 46   \n",
       "3  Liberal Party of Australia                 46   \n",
       "4  Liberal Party of Australia                 46   \n",
       "\n",
       "                                          lemma_text  \\\n",
       "0  get fundamental right lift game see thought pr...   \n",
       "1  state federal education minister set oppose el...   \n",
       "2       great support high education support package   \n",
       "3  ihea welcome todays announcement unveil suite ...   \n",
       "4  australian report iteca welcome australian gov...   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "0  get fundament right lift game see thought prio...   \n",
       "1  state feder educ minist set oppos element prop...   \n",
       "2           great support higher educ support packag   \n",
       "3  ihea welcom today announc unveil suit budget m...   \n",
       "4  australian report iteca welcom australian gove...   \n",
       "\n",
       "                                      lemma_text_sub  \\\n",
       "0         [lift, game, priority, curriculum, review]   \n",
       "1  [state, education, minister, element, school, ...   \n",
       "2             [support, education, support, package]   \n",
       "3  [welcome, announcement, suite, budget, measure...   \n",
       "4                   [report, government, support, …]   \n",
       "\n",
       "                                    stemmed_text_sub  \n",
       "0                 [game, nation, curriculum, review]  \n",
       "1  [state, feder, minist, element, school, curric...  \n",
       "2                         [support, support, packag]  \n",
       "3  [ihea, welcom, today, suit, budget, measur, pr...  \n",
       "4        [report, iteca, welcom, support, provid, …]  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"data/final_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "data_processing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
