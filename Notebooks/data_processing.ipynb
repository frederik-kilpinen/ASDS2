{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_processing.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frederik-kilpinen/ASDS2/blob/main/Notebooks/data_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TuJx9CUL0Kt"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymB9xub9L0K1"
      },
      "source": [
        "**By: Frederik, Connor, Matias, Lukas**\n",
        "\n",
        "This notebook contains all the data-processing steps taken before analysis is done. The data comes from two-sources:\n",
        "1. Meta Data about Australian parlamentarians(MPs) comes from the research project http://twitterpoliticians.org/download. We call this MP data.\n",
        "2. The latest 3200 tweets from Australian MPs that we have collected. We call this tweet data.\n",
        "\n",
        "In short we do the following preprocessing steps:\n",
        "\n",
        "1. Process the MP data by:\n",
        "    * subsetting relevant variables\n",
        "    * renaming Nick Xenophon Team to center alliance (its later name)\n",
        "    * removing titles such as Mr or Ms from MP names\n",
        "2. Merge the two data-sets\n",
        "3. Subset on MPs that were active MPs during the time of their tweet\n",
        "4. Subset on the time-period 1 year before the bushfire (1. June 2018) and 1 year after the bushfire (1. May 2021)\n",
        "5. clean the tweet text by:\n",
        "    * lower-casing the text\n",
        "    * remove special characters, punctuation, symbols, mentions, emojis\n",
        "    * remove english stop words (nltk)\n",
        "    * columns where we retain lemmas and stems\n",
        "    * columns where we retain part-of-speech from lemmas and stems\n",
        "\n",
        "\n",
        "The final data frame contains the following columns:\n",
        "\n",
        "* screen_name\n",
        "* user_id \n",
        "* tweet_id\n",
        "* created_at\n",
        "* full_text',\n",
        "* favorite_count\n",
        "* retweet_count\n",
        "* in_reply_to_screen_name',\n",
        "* hashtags\n",
        "* user_mentions\n",
        "* url\n",
        "* image_url\n",
        "* name\n",
        "* party\n",
        "* legislative_period\n",
        "* lemmas\n",
        "* stems\n",
        "* pos_lemmas \n",
        "* pos_stems\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5jNeH3d9cqY",
        "outputId": "2868b0be-964a-4c03-c748-45533972d2f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Necessary imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tweepy\n",
        "from datetime import date\n",
        "import pickle \n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from collections import defaultdict\n",
        "from textblob import TextBlob\n",
        "\n",
        "# If google colab:\n",
        "#nltk.download('wordnet')\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "#nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiXo-A0o9cqd"
      },
      "source": [
        "class DataProcessing:\n",
        "    \n",
        "    def __init__(self):\n",
        "        \n",
        "        #Set the file path. Change if necessary\n",
        "        #tweet_data_path = \"data/mp_tweets.csv\"\n",
        "        #mp_data_path = \"data/full_member_info.csv\"\n",
        "\n",
        "        tweet_data_path = \"/content/drive/MyDrive/Digital methods/mp_tweets\"\n",
        "        mp_data_path = \"/content/drive/MyDrive/Digital methods/full_member_info.csv\"\n",
        "\n",
        "        self.tweet_data = pd.read_csv(tweet_data_path, index_col = 0)\n",
        "        self.mp_data = pd.read_csv(mp_data_path)\n",
        "    \n",
        "    \n",
        "    def compile_final_df(self):\n",
        "        \"\"\"\n",
        "        This method compiles the final data-set used in our analysis. Doing the following steps:\n",
        "            1. Loads and \n",
        "        \n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        #Clean the Twitter data\n",
        "        tweet_df = self.clean_tweet_data(self.tweet_data)\n",
        "        #Clean the mp_info data\n",
        "        mp_df = self.clean_mp_data(self.mp_data)\n",
        "        \n",
        "        print(\"-\"*66)\n",
        "        print(f\"Shape of twitter data: {tweet_df.shape}\\nShape of MP data: {mp_df.shape}\")\n",
        "        \n",
        "        #Merge to final df\n",
        "        final_df = tweet_df.merge(mp_df, on = \"user_id\", how = \"left\")\n",
        "        \n",
        "        #Subset on active MPs\n",
        "        final_df = final_df.loc[((final_df[\"legislative_period\"] == \"45\") & (final_df[\"created_at\"] < \"2019-07-01\"))|\n",
        "                                ((final_df[\"legislative_period\"] == \"46\") & (final_df[\"created_at\"] > \"2019-07-01\"))]\n",
        "        \n",
        "        #Subset tweets from 1 year before the bushfire (1. June 2018) and 1 year after the bushfire (1. May 2021)\n",
        "        final_df = final_df.loc[(final_df[\"created_at\"] >= \"2018-06-01\") & (final_df[\"created_at\"] <= \"2021-04-30\")]\n",
        "           \n",
        "        #Restetting index for final df\n",
        "        final_df = final_df.reset_index(drop = True)\n",
        "        \n",
        "        print(\"-\"*66)\n",
        "        print(f\"Shape of final data-frame: {final_df.shape}\" )\n",
        "        print(\"Time to execute: \", \"--- %s seconds ---\" % (time.time() - start_time))\n",
        "        start_time = time.time()\n",
        "        print(\"-\"*66)\n",
        "        print(\"Begining to process the tweet text. Restarting timer...\")\n",
        "        \n",
        "        #Get the stems and lemmas\n",
        "        final_df[\"lemmas\"] = final_df[\"full_text\"].apply(lambda tweet: self.preprocess_lemma(tweet))\n",
        "        final_df[\"stems\"] = final_df[\"full_text\"].apply(lambda tweet: self.preprocess_stem(tweet))\n",
        "        \n",
        "        # replace the nan values with empty strings\n",
        "        final_df[\"lemmas\"] = final_df[\"lemmas\"].apply(lambda x: \"\" if str(x) == \"nan\" else x)\n",
        "        print(\"Lematizing finished at: \", \"--- %s seconds ---\" % (time.time() - start_time))\n",
        "        final_df[\"stems\"] = final_df[\"stems\"].apply(lambda x: \"\" if str(x) == \"nan\" else x)\n",
        "        print(\"Stemming finished at: \", \"--- %s seconds ---\" % (time.time() - start_time))\n",
        "        \n",
        "        #Create column of part-of-speech from lemmas and stems\n",
        "        final_df[\"pos_lemmas\"] = final_df[\"lemmas\"].apply(lambda tweet: self.get_pos(tweet))\n",
        "        final_df[\"pos_stems\"] = final_df[\"stems\"].apply(lambda tweet: self.get_pos(tweet))\n",
        "        \n",
        "        print(\"-\"*66)\n",
        "        print(\"FINISHED: time to execute: \", \"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "        return final_df\n",
        "\n",
        "    def clean_tweet_data(self, tweet_df):\n",
        "\n",
        "\n",
        "        #Drop 6 tweets that are corrupt. Because of it only being 6 tweets we drop them instead of re-running the collection from the API\n",
        "        remove_idx = [175522, 190414, 211953, 212012, 212013, 212298 ]\n",
        "        tweet_df = tweet_df.drop(tweet_df.index[remove_idx])\n",
        "\n",
        "        #Make data into date-time object, remove h-m-s from dt\n",
        "        tweet_df[\"created_at\"] = pd.to_datetime(pd.to_datetime(tweet_df[\"created_at\"]).dt.date)\n",
        "        \n",
        "        tweet_df[\"user_id\"] = tweet_df[\"user_id\"].astype(int)\n",
        "        \n",
        "        return tweet_df\n",
        "    \n",
        "    def clean_mp_data(self, mp_df):\n",
        "        \n",
        "        #Select relevant columns\n",
        "        mp_df = mp_df[['p.country', 'm.name', 'p.party', 'm.uid', 'lp.official_legislative_period']]\n",
        "        mp_df = mp_df.loc[mp_df[\"p.country\"]==\"Australia\"]\n",
        "        \n",
        "        #Drop australia column\n",
        "        mp_df = mp_df.drop(columns = [\"p.country\"])\n",
        "        #Rename some columns\n",
        "        mp_df = mp_df.rename(columns = {\"m.name\":\"name\", \"p.party\":\"party\",\n",
        "                                       \"lp.official_legislative_period\":\"legislative_period\"})\n",
        "        \n",
        "        #Rename user id column for merging with members_info data\n",
        "        mp_df = mp_df.rename(columns = {\"m.uid\":\"user_id\"})\n",
        "        \n",
        "        #remove titles from the names\n",
        "        remove = r\"(^[A-Za-z]{2}\\s{1}|\\s{1}[A-Z]{2,}|^Hon\\s{1}|^Mrs\\s{1}|(Dr\\s)|,)\"\n",
        "        mp_df[\"name\"] = mp_df[\"name\"].str.replace(remove, \"\", regex = True)\n",
        "        \n",
        "        #remove mps that don't have twitter\n",
        "        mp_df = mp_df.loc[mp_df[\"user_id\"] != \"\\\\N\"]\n",
        "        mp_df[\"user_id\"] = mp_df[\"user_id\"].astype(int)\n",
        "        \n",
        "        # Merge the Nick Xenophon Team and Centre Alliance \n",
        "        mp_df[\"party\"] = mp_df[\"party\"].apply(lambda x: \"Centre Alliance\" if x == \"Nick Xenophon Team\" else x)\n",
        "        \n",
        "        return mp_df\n",
        "    \n",
        "    def preprocess_text(self, text):\n",
        "\n",
        "        #Lowercasing words\n",
        "        text = str(text)\n",
        "        text = text.lower()\n",
        "\n",
        "        #Removing '&amp' which was found to be common\n",
        "        text = re.sub(r'&amp','', text)\n",
        "\n",
        "        #Replace other instances of \"&\" with \"and\"\n",
        "        text = re.sub(r'&','and', text)\n",
        "\n",
        "        #Removing mentions \n",
        "        text = re.sub(r'@\\w+ ', '', text)\n",
        "\n",
        "        #Removing 'RT' and 'via'\n",
        "        text = re.sub(r'(^rt|^via)((?:\\b\\W*@\\w+)+): ', '', text)\n",
        "\n",
        "        #Removing emojis\n",
        "        EMOJI_PATTERN = re.compile(\n",
        "          \"[\"\n",
        "          \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "          \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "          \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "          \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "          \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
        "          \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
        "          \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
        "          \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
        "          \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
        "          \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
        "          \"\\U00002702-\\U000027B0\"  # Dingbats\n",
        "          \"\\U000024C2-\\U0001F251\" \n",
        "          \"]+\"\n",
        "          )\n",
        "        \n",
        "        text = re.sub(EMOJI_PATTERN, '', text)\n",
        "\n",
        "        #Removing punctuation\n",
        "        my_punctuation = string.punctuation.replace('#','')\n",
        "        my_punctuation = my_punctuation.replace('-','')\n",
        "\n",
        "        text = text.translate(str.maketrans('', '', my_punctuation))\n",
        "        text = re.sub(r' - ','', text) #removing dash lines bounded by whitespace (and therefore not part of a word)\n",
        "        text = re.sub(r'[’“”—,!]','',text) #removing punctuation that is not captured by string.punctuation\n",
        "\n",
        "        #Removing odd special characters\n",
        "        text = re.sub(r\"[┻┃━┳┓┏┛┗]\",\"\", text)\n",
        "        text = re.sub(r\"\\u202F|\\u2069|\\u200d|\\u2066\",\"\", text)\n",
        "\n",
        "        #Removing URLs\n",
        "        text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "        #Removing numbers\n",
        "        text = re.sub(r'[0-9]','', text)\n",
        "\n",
        "        #Removing separators and superfluous whitespace\n",
        "        text = text.strip()\n",
        "        text = re.sub(r' +',' ',text)\n",
        "\n",
        "        #Tokenizing\n",
        "        tokenizer = TweetTokenizer()\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "\n",
        "    def preprocess_lemma(self, tokens):\n",
        "\n",
        "        #Running the preprocess function\n",
        "        tokens = self.preprocess_text(tokens)\n",
        "\n",
        "        #Lemmatizing\n",
        "        tag_map = defaultdict(lambda : nltk.corpus.wordnet.NOUN)      #POS map\n",
        "        tag_map['J'] = nltk.corpus.wordnet.ADJ\n",
        "        tag_map['V'] = nltk.corpus.wordnet.VERB\n",
        "        tag_map['R'] = nltk.corpus.wordnet.ADV    \n",
        "\n",
        "        lemmatizer = nltk.WordNetLemmatizer()             #Creating lemmatizer.\n",
        "        text_lemmatized = []                              #Empty list to save lemmatized sentence\n",
        "\n",
        "        for word, tag in nltk.pos_tag(tokens):\n",
        "            lemma = lemmatizer.lemmatize(word, tag_map[tag[0]])\n",
        "            text_lemmatized.append(lemma)\n",
        "\n",
        "        tokens = text_lemmatized\n",
        "\n",
        "        #Removing stopwords\n",
        "        stop_words_list = nltk.corpus.stopwords.words(\"english\")\n",
        "        text = \" \".join([i for i in tokens if i not in stop_words_list])\n",
        "\n",
        "        return text\n",
        "\n",
        "    def preprocess_stem(self, tokens):\n",
        "\n",
        "        #Running the preprocess function\n",
        "        tokens = self.preprocess_text(tokens)\n",
        "\n",
        "        #Removing stopwords\n",
        "        stop_words_list = nltk.corpus.stopwords.words(\"english\")\n",
        "        tokens = [i for i in tokens if i not in stop_words_list]\n",
        "\n",
        "        #Stemming\n",
        "        stemmer = nltk.PorterStemmer()    #Creating stemmer\n",
        "        sent_stemmed = []                 #Empty list to save stemmed sentence\n",
        "\n",
        "        for word in tokens:\n",
        "            stem = stemmer.stem(word)     #Stemming words\n",
        "            sent_stemmed.append(stem)\n",
        "\n",
        "        tokens = sent_stemmed\n",
        "\n",
        "        return \" \".join(tokens)\n",
        "    \n",
        "    \n",
        "    def get_pos(self, text):\n",
        "        blob = TextBlob(text)\n",
        "        pos = [word for (word,tag) in blob.tags if tag in [\"NN\", \"NNP\", \"VD\"]]\n",
        "        \n",
        "        return \" \".join(pos)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiQmYnQI9cqe",
        "outputId": "12b92443-b681-46df-c794-91193afe0a5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "processor = DataProcessing()\n",
        "final_df = processor.compile_final_df()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (0,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------\n",
            "Shape of twitter data: (335969, 12)\n",
            "Shape of MP data: (258, 4)\n",
            "------------------------------------------------------------------\n",
            "Shape of final data-frame: (170338, 15)\n",
            "Time to execute:  --- 0.9455933570861816 seconds ---\n",
            "------------------------------------------------------------------\n",
            "Begining to process the tweet text. Restarting timer...\n",
            "Lematizing finished at:  --- 354.2302391529083 seconds ---\n",
            "Stemming finished at:  --- 354.2888534069061 seconds ---\n",
            "------------------------------------------------------------------\n",
            "FINISHED: time to execute:  --- 735.1697945594788 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zTx6WmcL0LE",
        "outputId": "f6c3dddb-940b-4f2c-c7b4-dbd8247638b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "final_df.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(170338, 19)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fB8sfnWL0LG",
        "outputId": "7688526b-a42e-442f-90fb-f104e7a8866b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "final_df.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>screen_name</th>\n",
              "      <th>user_id</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>full_text</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>in_reply_to_screen_name</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>user_mentions</th>\n",
              "      <th>url</th>\n",
              "      <th>image_url</th>\n",
              "      <th>name</th>\n",
              "      <th>party</th>\n",
              "      <th>legislative_period</th>\n",
              "      <th>lemmas</th>\n",
              "      <th>stems</th>\n",
              "      <th>pos_lemmas</th>\n",
              "      <th>pos_stems</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AlanTudgeMP</td>\n",
              "      <td>185932331</td>\n",
              "      <td>1.388275e+18</td>\n",
              "      <td>2021-04-30</td>\n",
              "      <td>Get the fundamentals right and lift our game. ...</td>\n",
              "      <td>18</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://www.theaustralian.com.au/inquirer/get-...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alan Tudge</td>\n",
              "      <td>Liberal Party of Australia</td>\n",
              "      <td>46</td>\n",
              "      <td>get fundamental right lift game see thought pr...</td>\n",
              "      <td>get fundament right lift game see thought prio...</td>\n",
              "      <td>lift game priority curriculum review</td>\n",
              "      <td>game nation curriculum review</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AlanTudgeMP</td>\n",
              "      <td>185932331</td>\n",
              "      <td>1.388274e+18</td>\n",
              "      <td>2021-04-30</td>\n",
              "      <td>RT @australian: State and federal education mi...</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>['australian']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alan Tudge</td>\n",
              "      <td>Liberal Party of Australia</td>\n",
              "      <td>46</td>\n",
              "      <td>state federal education minister set oppose el...</td>\n",
              "      <td>state feder educ minist set oppos element prop...</td>\n",
              "      <td>state education minister element school curric...</td>\n",
              "      <td>state feder minist element school curriculum b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AlanTudgeMP</td>\n",
              "      <td>185932331</td>\n",
              "      <td>1.388039e+18</td>\n",
              "      <td>2021-04-30</td>\n",
              "      <td>Great support for our $53m Higher Education su...</td>\n",
              "      <td>12</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://twitter.com/ITECAust/status/1387941814...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alan Tudge</td>\n",
              "      <td>Liberal Party of Australia</td>\n",
              "      <td>46</td>\n",
              "      <td>great support high education support package</td>\n",
              "      <td>great support higher educ support packag</td>\n",
              "      <td>support education support package</td>\n",
              "      <td>support support packag</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AlanTudgeMP</td>\n",
              "      <td>185932331</td>\n",
              "      <td>1.388035e+18</td>\n",
              "      <td>2021-04-30</td>\n",
              "      <td>RT @IndependentHEA: IHEA welcomes today’s anno...</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>['IndependentHEA', 'AlanTudgeMP', 'stuartrober...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alan Tudge</td>\n",
              "      <td>Liberal Party of Australia</td>\n",
              "      <td>46</td>\n",
              "      <td>ihea welcome todays announcement unveil suite ...</td>\n",
              "      <td>ihea welcom today announc unveil suit budget m...</td>\n",
              "      <td>welcome announcement suite budget measure …</td>\n",
              "      <td>ihea welcom today suit budget measur provid …</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AlanTudgeMP</td>\n",
              "      <td>185932331</td>\n",
              "      <td>1.388031e+18</td>\n",
              "      <td>2021-04-30</td>\n",
              "      <td>RT @ITECAust: The Australian — As @TimDoddEDU ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>['ITECAust', 'TimDoddEDU']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alan Tudge</td>\n",
              "      <td>Liberal Party of Australia</td>\n",
              "      <td>46</td>\n",
              "      <td>australian report iteca welcome australian gov...</td>\n",
              "      <td>australian report iteca welcom australian gove...</td>\n",
              "      <td>report government support …</td>\n",
              "      <td>report iteca welcom support provid …</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   screen_name  ...                                          pos_stems\n",
              "0  AlanTudgeMP  ...                      game nation curriculum review\n",
              "1  AlanTudgeMP  ...  state feder minist element school curriculum b...\n",
              "2  AlanTudgeMP  ...                             support support packag\n",
              "3  AlanTudgeMP  ...      ihea welcom today suit budget measur provid …\n",
              "4  AlanTudgeMP  ...               report iteca welcom support provid …\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT50yqLvL0LH"
      },
      "source": [
        "final_df.to_csv(\"data/final_df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}