{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_processing.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frederik-kilpinen/ASDS2/blob/main/Notebooks/data_processing_bigrams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TuJx9CUL0Kt"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymB9xub9L0K1"
      },
      "source": [
        "**By: Frederik, Connor, Matias, Lukas**\n",
        "\n",
        "This notebook contains all the data-processing steps taken before analysis is done. The data comes from two-sources:\n",
        "1. Meta Data about Australian parlamentarians(MPs) comes from the research project http://twitterpoliticians.org/download. We call this MP data.\n",
        "2. The latest 3200 tweets from Australian MPs that we have collected. We call this tweet data.\n",
        "\n",
        "In short we do the following preprocessing steps:\n",
        "\n",
        "1. Process the MP data by:\n",
        "    * subsetting relevant variables\n",
        "    * renaming Nick Xenophon Team to center alliance (its later name)\n",
        "    * removing titles such as Mr or Ms from MP names\n",
        "2. Merge the two data-sets\n",
        "3. Subset on MPs that were active MPs during the time of their tweet\n",
        "4. Subset on the time-period 1 year before the bushfire (1. June 2018) and 1 year after the bushfire (1. May 2021)\n",
        "5. clean the tweet text by:\n",
        "    * lower-casing the text\n",
        "    * remove special characters, punctuation, symbols, mentions, emojis\n",
        "    * remove english stop words (nltk)\n",
        "    * columns where we retain lemmas and stems\n",
        "    * columns where we retain part-of-speech from lemmas and stems\n",
        "\n",
        "\n",
        "The final data frame contains the following columns:\n",
        "\n",
        "* screen_name\n",
        "* user_id \n",
        "* tweet_id\n",
        "* created_at\n",
        "* full_text',\n",
        "* favorite_count\n",
        "* retweet_count\n",
        "* in_reply_to_screen_name',\n",
        "* hashtags\n",
        "* user_mentions\n",
        "* url\n",
        "* image_url\n",
        "* name\n",
        "* party\n",
        "* legislative_period\n",
        "* lemmas\n",
        "* stems\n",
        "* pos_lemmas \n",
        "* pos_stems\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5jNeH3d9cqY",
        "outputId": "3b3cd7d6-614d-4094-db23-fd5ea14042b4"
      },
      "source": [
        "#Necessary imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tweepy\n",
        "from datetime import date\n",
        "import pickle \n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from collections import defaultdict\n",
        "from textblob import TextBlob\n",
        "\n",
        "# If google colab:\n",
        "#!pip install nltk==3.4\n",
        "#nltk.download('wordnet')\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "#nltk.download('stopwords')\n",
        "#nltk.download('punkt')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk==3.4 in /usr/local/lib/python3.7/dist-packages (3.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4) (1.15.0)\n",
            "Requirement already satisfied: singledispatch in /usr/local/lib/python3.7/dist-packages (from nltk==3.4) (3.6.2)\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiXo-A0o9cqd"
      },
      "source": [
        "class DataProcessing:\n",
        "    \n",
        "    def __init__(self):\n",
        "        \n",
        "        #Set the file path. Change if necessary\n",
        "        tweet_data_path = \"data/mp_tweets.csv\"\n",
        "        mp_data_path = \"data/full_member_info.csv\"\n",
        "\n",
        "        self.tweet_data = pd.read_csv(tweet_data_path, index_col = 0)\n",
        "        self.mp_data = pd.read_csv(mp_data_path)\n",
        "    \n",
        "    \n",
        "    def compile_final_df(self):\n",
        "        \"\"\"\n",
        "        This method compiles the final data-set used in our analysis. Doing the following steps:\n",
        "            1. Loads and \n",
        "        \n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        #Clean the Twitter data\n",
        "        tweet_df = self.clean_tweet_data(self.tweet_data)\n",
        "        #Clean the mp_info data\n",
        "        mp_df = self.clean_mp_data(self.mp_data)\n",
        "        \n",
        "        print(\"-\"*66)\n",
        "        print(f\"Shape of twitter data: {tweet_df.shape}\\nShape of MP data: {mp_df.shape}\")\n",
        "        \n",
        "        #Merge to final df\n",
        "        final_df = tweet_df.merge(mp_df, on = \"user_id\", how = \"left\")\n",
        "        final_df = final_df.sample(n=300)\n",
        "        \n",
        "        #Subset on active MPs\n",
        "        final_df = final_df.loc[((final_df[\"legislative_period\"] == \"45\") & (final_df[\"created_at\"] < \"2019-07-01\"))|\n",
        "                                ((final_df[\"legislative_period\"] == \"46\") & (final_df[\"created_at\"] > \"2019-07-01\"))]\n",
        "        \n",
        "        #Subset tweets from 1 year before the bushfire (1. June 2018) and 1 year after the bushfire (1. May 2021)\n",
        "        final_df = final_df.loc[(final_df[\"created_at\"] >= \"2018-06-01\") & (final_df[\"created_at\"] <= \"2021-04-30\")]\n",
        "           \n",
        "        #Restetting index for final df\n",
        "        final_df = final_df.reset_index(drop = True)\n",
        "        \n",
        "        print(\"-\"*66)\n",
        "        print(f\"Shape of final data-frame: {final_df.shape}\" )\n",
        "        print(\"Time to execute: \", \"--- %s seconds ---\" % (time.time() - start_time))\n",
        "        start_time = time.time()\n",
        "        print(\"-\"*66)\n",
        "        print(\"Begining to process the tweet text. Restarting timer...\")\n",
        "        \n",
        "        #Get the stems and lemmas\n",
        "        #final_df[\"lemmas\"] = final_df[\"full_text\"].apply(lambda tweet: self.preprocess_lemma(tweet))\n",
        "        final_df[\"stems\"] = final_df[\"full_text\"].apply(lambda tweet: self.preprocess_stem(tweet))\n",
        "\n",
        "        # Sreating stemmed bigrams\n",
        "        def join_tups(lst):\n",
        "          return ['_'.join(tup) for tup in lst]\n",
        "        final_df[\"stems_bigram\"] = final_df[\"stems\"].apply(lambda x: nltk.bigrams(x))\n",
        "        final_df[\"stems\"] = final_df[\"stems\"] + final_df[\"stems_bigram\"].apply(lambda x: join_tups(x))\n",
        "\n",
        "        # replace the nan values with empty strings\n",
        "        #final_df[\"lemmas\"] = final_df[\"lemmas\"].apply(lambda x: \"\" if str(x) == \"nan\" else x)\n",
        "        #print(\"Lematizing finished at: \", \"--- %s seconds ---\" % (time.time() - start_time))\n",
        "        final_df[\"stems\"] = final_df[\"stems\"].apply(lambda x: \"\" if str(x) == \"nan\" else x)\n",
        "        print(\"Stemming finished at: \", \"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "        \n",
        "        \n",
        "        #Create column of part-of-speech from lemmas and stems\n",
        "        #final_df[\"pos_lemmas\"] = final_df[\"lemmas\"].apply(lambda tweet: self.get_pos(tweet))\n",
        "        #final_df[\"pos_stems\"] = final_df[\"stems\"].apply(lambda tweet: self.get_pos(tweet))\n",
        "        \n",
        "        print(\"-\"*66)\n",
        "        print(\"FINISHED: time to execute: \", \"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "        return final_df\n",
        "\n",
        "    def clean_tweet_data(self, tweet_df):\n",
        "\n",
        "\n",
        "        #Drop 6 tweets that are corrupt. Because of it only being 6 tweets we drop them instead of re-running the collection from the API\n",
        "        remove_idx = [175522, 190414, 211953, 212012, 212013, 212298 ]\n",
        "        tweet_df = tweet_df.drop(tweet_df.index[remove_idx])\n",
        "\n",
        "        #Make data into date-time object, remove h-m-s from dt\n",
        "        tweet_df[\"created_at\"] = pd.to_datetime(pd.to_datetime(tweet_df[\"created_at\"]).dt.date)\n",
        "        \n",
        "        tweet_df[\"user_id\"] = tweet_df[\"user_id\"].astype(int)\n",
        "        \n",
        "        return tweet_df\n",
        "    \n",
        "    def clean_mp_data(self, mp_df):\n",
        "        \n",
        "        #Select relevant columns\n",
        "        mp_df = mp_df[['p.country', 'm.name', 'p.party', 'm.uid', 'lp.official_legislative_period']]\n",
        "        mp_df = mp_df.loc[mp_df[\"p.country\"]==\"Australia\"]\n",
        "        \n",
        "        #Drop australia column\n",
        "        mp_df = mp_df.drop(columns = [\"p.country\"])\n",
        "        #Rename some columns\n",
        "        mp_df = mp_df.rename(columns = {\"m.name\":\"name\", \"p.party\":\"party\",\n",
        "                                       \"lp.official_legislative_period\":\"legislative_period\"})\n",
        "        \n",
        "        #Rename user id column for merging with members_info data\n",
        "        mp_df = mp_df.rename(columns = {\"m.uid\":\"user_id\"})\n",
        "        \n",
        "        #remove titles from the names\n",
        "        remove = r\"(^[A-Za-z]{2}\\s{1}|\\s{1}[A-Z]{2,}|^Hon\\s{1}|^Mrs\\s{1}|(Dr\\s)|,)\"\n",
        "        mp_df[\"name\"] = mp_df[\"name\"].str.replace(remove, \"\", regex = True)\n",
        "        \n",
        "        #remove mps that don't have twitter\n",
        "        mp_df = mp_df.loc[mp_df[\"user_id\"] != \"\\\\N\"]\n",
        "        mp_df[\"user_id\"] = mp_df[\"user_id\"].astype(int)\n",
        "        \n",
        "        # Merge the Nick Xenophon Team and Centre Alliance \n",
        "        mp_df[\"party\"] = mp_df[\"party\"].apply(lambda x: \"Centre Alliance\" if x == \"Nick Xenophon Team\" else x)\n",
        "        \n",
        "        return mp_df\n",
        "    \n",
        "    def preprocess_text(self, text):\n",
        "\n",
        "        #Lowercasing words\n",
        "        text = str(text)\n",
        "        text = text.lower()\n",
        "\n",
        "        #Removing '&amp' which was found to be common\n",
        "        text = re.sub(r'&amp','', text)\n",
        "\n",
        "        #Replace other instances of \"&\" with \"and\"\n",
        "        text = re.sub(r'&','and', text)\n",
        "\n",
        "        #Removing mentions \n",
        "        text = re.sub(r'@\\w+ ', '', text)\n",
        "\n",
        "        #Removing 'RT' and 'via'\n",
        "        text = re.sub(r'(^rt|^via)((?:\\b\\W*@\\w+)+): ', '', text)\n",
        "\n",
        "        #Removing emojis\n",
        "        EMOJI_PATTERN = re.compile(\n",
        "          \"[\"\n",
        "          \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "          \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "          \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "          \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "          \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
        "          \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
        "          \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
        "          \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
        "          \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
        "          \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
        "          \"\\U00002702-\\U000027B0\"  # Dingbats\n",
        "          \"\\U000024C2-\\U0001F251\" \n",
        "          \"]+\"\n",
        "          )\n",
        "        \n",
        "        text = re.sub(EMOJI_PATTERN, '', text)\n",
        "\n",
        "        #Removing punctuation\n",
        "        my_punctuation = string.punctuation.replace('#','')\n",
        "        my_punctuation = my_punctuation.replace('-','')\n",
        "\n",
        "        text = text.translate(str.maketrans('', '', my_punctuation))\n",
        "        text = re.sub(r' - ','', text) #removing dash lines bounded by whitespace (and therefore not part of a word)\n",
        "        text = re.sub(r'[’“”—,!]','',text) #removing punctuation that is not captured by string.punctuation\n",
        "\n",
        "        #Removing odd special characters\n",
        "        text = re.sub(r\"[┻┃━┳┓┏┛┗]\",\"\", text)\n",
        "        text = re.sub(r\"\\u202F|\\u2069|\\u200d|\\u2066\",\"\", text)\n",
        "\n",
        "        #Removing URLs\n",
        "        text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "        #Removing numbers\n",
        "        text = re.sub(r'[0-9]','', text)\n",
        "\n",
        "        #Removing separators and superfluous whitespace\n",
        "        text = text.strip()\n",
        "        text = re.sub(r' +',' ',text)\n",
        "\n",
        "        #Tokenizing\n",
        "        tokenizer = TweetTokenizer()\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "\n",
        "    #def preprocess_lemma(self, tokens):\n",
        "\n",
        "        #Running the preprocess function\n",
        "        #tokens = self.preprocess_text(tokens)\n",
        "\n",
        "        #Lemmatizing\n",
        "        #tag_map = defaultdict(lambda : nltk.corpus.wordnet.NOUN)      #POS map\n",
        "        #tag_map['J'] = nltk.corpus.wordnet.ADJ\n",
        "        #tag_map['V'] = nltk.corpus.wordnet.VERB\n",
        "        #tag_map['R'] = nltk.corpus.wordnet.ADV    \n",
        "\n",
        "        #lemmatizer = nltk.WordNetLemmatizer()             #Creating lemmatizer.\n",
        "        #text_lemmatized = []                              #Empty list to save lemmatized sentence\n",
        "\n",
        "        #for word, tag in nltk.pos_tag(tokens):\n",
        "        #    lemma = lemmatizer.lemmatize(word, tag_map[tag[0]])\n",
        "        #    text_lemmatized.append(lemma)\n",
        "\n",
        "        #tokens = text_lemmatized\n",
        "\n",
        "        #Removing stopwords\n",
        "        #stop_words_list = nltk.corpus.stopwords.words(\"english\")\n",
        "        #text = \" \".join([i for i in tokens if i not in stop_words_list])\n",
        "\n",
        "        #return text\n",
        "\n",
        "    def preprocess_stem(self, tokens):\n",
        "\n",
        "        #Running the preprocess function\n",
        "        tokens = self.preprocess_text(tokens)\n",
        "\n",
        "        #Removing stopwords\n",
        "        stop_words_list = nltk.corpus.stopwords.words(\"english\")\n",
        "        tokens = [i for i in tokens if i not in stop_words_list]\n",
        "\n",
        "        #Stemming\n",
        "        stemmer = nltk.PorterStemmer()    #Creating stemmer\n",
        "        sent_stemmed = []                 #Empty list to save stemmed sentence\n",
        "\n",
        "        for word in tokens:\n",
        "            stem = stemmer.stem(word)     #Stemming words\n",
        "            sent_stemmed.append(stem)\n",
        "\n",
        "        tokens = sent_stemmed\n",
        "\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    \n",
        "    def get_pos(self, text):\n",
        "        blob = TextBlob(text)\n",
        "        pos = [word for (word,tag) in blob.tags if tag in [\"NN\", \"NNP\", \"VD\"]]\n",
        "        \n",
        "        return \" \".join(pos)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "OiQmYnQI9cqe",
        "outputId": "8ce013cb-dedc-4466-8c9e-2601550e774a"
      },
      "source": [
        "processor = DataProcessing()\n",
        "final_df = processor.compile_final_df()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (0,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------\n",
            "Shape of twitter data: (335969, 12)\n",
            "Shape of MP data: (258, 4)\n",
            "------------------------------------------------------------------\n",
            "Shape of final data-frame: (71, 15)\n",
            "Time to execute:  --- 0.7883164882659912 seconds ---\n",
            "------------------------------------------------------------------\n",
            "Begining to process the tweet text. Restarting timer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/util.py\u001b[0m in \u001b[0;36mngrams\u001b[0;34m(sequence, n, pad_left, pad_right, left_pad_symbol, right_pad_symbol)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m     \"\"\"\n\u001b[0m\u001b[1;32m    469\u001b[0m     \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: ",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-45271b4e427d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataProcessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfinal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_final_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-dfed6b5a6b16>\u001b[0m in \u001b[0;36mcompile_final_df\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems_bigram\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems_bigram\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjoin_tups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# replace the nan values with empty strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4212\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4213\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-dfed6b5a6b16>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     58\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems_bigram\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems_bigram\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjoin_tups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# replace the nan values with empty strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-dfed6b5a6b16>\u001b[0m in \u001b[0;36mjoin_tups\u001b[0;34m(lst)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Sreating stemmed bigrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mjoin_tups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems_bigram\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems_bigram\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjoin_tups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-dfed6b5a6b16>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Sreating stemmed bigrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mjoin_tups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems_bigram\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stems_bigram\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjoin_tups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/util.py\u001b[0m in \u001b[0;36mbigrams\u001b[0;34m(sequence, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mngrams\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0ma\u001b[0m \u001b[0msequence\u001b[0m \u001b[0mof\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0man\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0mFor\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: generator raised StopIteration"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYe0xDKMoLT7",
        "outputId": "ed1f4883-8dcb-400e-ba69-f2e8b872f6ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "final_df"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>screen_name</th>\n",
              "      <th>user_id</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>full_text</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>in_reply_to_screen_name</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>user_mentions</th>\n",
              "      <th>url</th>\n",
              "      <th>image_url</th>\n",
              "      <th>name</th>\n",
              "      <th>party</th>\n",
              "      <th>legislative_period</th>\n",
              "      <th>stems</th>\n",
              "      <th>stems_bigram</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M_McCormackMP</td>\n",
              "      <td>1195051945</td>\n",
              "      <td>1.263337e+18</td>\n",
              "      <td>2020-05-21</td>\n",
              "      <td>We are determined to ensure the future of avia...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>['ITECAust']</td>\n",
              "      <td>https://twitter.com/ITECAust/status/1263327037...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Michael McCormack</td>\n",
              "      <td>The Nationals</td>\n",
              "      <td>46</td>\n",
              "      <td>[determin, ensur, futur, aviat, strong, side, ...</td>\n",
              "      <td>&lt;generator object bigrams at 0x7fd8d5a41c50&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MarkCoultonMP</td>\n",
              "      <td>481708709</td>\n",
              "      <td>1.207395e+18</td>\n",
              "      <td>2019-12-18</td>\n",
              "      <td>RT @GregHuntMP: Today's $8.9m for 24 cancer re...</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>['GregHuntMP']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mark Coulton</td>\n",
              "      <td>The Nationals</td>\n",
              "      <td>46</td>\n",
              "      <td>[today, cancer, research, project, game-chang,...</td>\n",
              "      <td>&lt;generator object bigrams at 0x7fd8d5a41e50&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ShayneNeumannMP</td>\n",
              "      <td>117717402</td>\n",
              "      <td>1.044878e+18</td>\n",
              "      <td>2018-09-26</td>\n",
              "      <td>RT @MRowlandMP: This internal inquiry is a whi...</td>\n",
              "      <td>0</td>\n",
              "      <td>364.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>['MRowlandMP']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Shayne Neumann</td>\n",
              "      <td>Australian Labor Party</td>\n",
              "      <td>45</td>\n",
              "      <td>[intern, inquiri, whitewash, design, shield, f...</td>\n",
              "      <td>&lt;generator object bigrams at 0x7fd8d5a41ed0&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KevinHoganMP</td>\n",
              "      <td>859024531</td>\n",
              "      <td>1.189992e+18</td>\n",
              "      <td>2019-10-31</td>\n",
              "      <td>BONALBO CENTRAL SCHOOL \\n\\nWonderful to be the...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://www.facebook.com/356113427813761/posts...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Kevin Hogan</td>\n",
              "      <td>The Nationals</td>\n",
              "      <td>46</td>\n",
              "      <td>[bonalbo, central, school, wonder, week, check...</td>\n",
              "      <td>&lt;generator object bigrams at 0x7fd8d5a41f50&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M_McCormackMP</td>\n",
              "      <td>1195051945</td>\n",
              "      <td>1.126336e+18</td>\n",
              "      <td>2019-05-09</td>\n",
              "      <td>Regional tourism creates jobs for country comm...</td>\n",
              "      <td>11</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['Oberon', 'Tarana', 'WombatTrail', 'PuttingLo...</td>\n",
              "      <td>['The_Nationals']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Michael McCormack</td>\n",
              "      <td>The Nationals</td>\n",
              "      <td>45</td>\n",
              "      <td>[region, tourism, creat, job, countri, commun,...</td>\n",
              "      <td>&lt;generator object bigrams at 0x7fd8d59d6050&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>mattkeogh</td>\n",
              "      <td>18826874</td>\n",
              "      <td>1.240620e+18</td>\n",
              "      <td>2020-03-19</td>\n",
              "      <td>RT @womblesofficial: Thank you to all the heal...</td>\n",
              "      <td>0</td>\n",
              "      <td>525.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>['womblesofficial']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Matt Keogh</td>\n",
              "      <td>Australian Labor Party</td>\n",
              "      <td>46</td>\n",
              "      <td>[thank, healthcar, worker, polic, shop, worker...</td>\n",
              "      <td>&lt;generator object bigrams at 0x7fd8d59dbc50&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>markdreyfusQCMP</td>\n",
              "      <td>4846185439</td>\n",
              "      <td>1.092605e+18</td>\n",
              "      <td>2019-02-05</td>\n",
              "      <td>A message delivered with devastating force by ...</td>\n",
              "      <td>100</td>\n",
              "      <td>58.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://www.theguardian.com/environment/2019/f...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mark Dreyfus</td>\n",
              "      <td>Australian Labor Party</td>\n",
              "      <td>45</td>\n",
              "      <td>[messag, deliv, devast, forc, richard, flanaga...</td>\n",
              "      <td>&lt;generator object bigrams at 0x7fd8d59dbcd0&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>Mark_Butler_MP</td>\n",
              "      <td>220883243</td>\n",
              "      <td>1.034622e+18</td>\n",
              "      <td>2018-08-29</td>\n",
              "      <td>At the next election the choice has never been...</td>\n",
              "      <td>212</td>\n",
              "      <td>146.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['auspol']</td>\n",
              "      <td>[]</td>\n",
              "      <td>http://thebigsmoke.com.au/2018/08/29/morrisons...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mark Butler</td>\n",
              "      <td>Australian Labor Party</td>\n",
              "      <td>45</td>\n",
              "      <td>[next, elect, choic, never, clearer, shorten, ...</td>\n",
              "      <td>&lt;generator object bigrams at 0x7fd8d59dbd50&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>JoanneRyanLalor</td>\n",
              "      <td>1631812358</td>\n",
              "      <td>1.208559e+18</td>\n",
              "      <td>2019-12-22</td>\n",
              "      <td>RT @AmandaRishworth: Unfortunately it seems th...</td>\n",
              "      <td>0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>['AmandaRishworth']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Joanne Ryan</td>\n",
              "      <td>Australian Labor Party</td>\n",
              "      <td>46</td>\n",
              "      <td>[unfortun, seem, morrison, govern, quick, acti...</td>\n",
              "      <td>&lt;generator object bigrams at 0x7fd8d59dbdd0&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>MerylSwanson</td>\n",
              "      <td>1586960762</td>\n",
              "      <td>1.074952e+18</td>\n",
              "      <td>2018-12-18</td>\n",
              "      <td>Nearly nine million Australians live in region...</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://www.facebook.com/309053992482798/posts...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Meryl Swanson</td>\n",
              "      <td>Australian Labor Party</td>\n",
              "      <td>45</td>\n",
              "      <td>[nearli, nine, million, australian, live, regi...</td>\n",
              "      <td>&lt;generator object bigrams at 0x7fd8d59dbe50&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>95 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        screen_name  ...                                  stems_bigram\n",
              "0     M_McCormackMP  ...  <generator object bigrams at 0x7fd8d5a41c50>\n",
              "1     MarkCoultonMP  ...  <generator object bigrams at 0x7fd8d5a41e50>\n",
              "2   ShayneNeumannMP  ...  <generator object bigrams at 0x7fd8d5a41ed0>\n",
              "3      KevinHoganMP  ...  <generator object bigrams at 0x7fd8d5a41f50>\n",
              "4     M_McCormackMP  ...  <generator object bigrams at 0x7fd8d59d6050>\n",
              "..              ...  ...                                           ...\n",
              "90        mattkeogh  ...  <generator object bigrams at 0x7fd8d59dbc50>\n",
              "91  markdreyfusQCMP  ...  <generator object bigrams at 0x7fd8d59dbcd0>\n",
              "92   Mark_Butler_MP  ...  <generator object bigrams at 0x7fd8d59dbd50>\n",
              "93  JoanneRyanLalor  ...  <generator object bigrams at 0x7fd8d59dbdd0>\n",
              "94     MerylSwanson  ...  <generator object bigrams at 0x7fd8d59dbe50>\n",
              "\n",
              "[95 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zTx6WmcL0LE",
        "outputId": "f6c3dddb-940b-4f2c-c7b4-dbd8247638b4"
      },
      "source": [
        "final_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(170338, 19)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "_fB8sfnWL0LG",
        "outputId": "7688526b-a42e-442f-90fb-f104e7a8866b"
      },
      "source": [
        "final_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>screen_name</th>\n",
              "      <th>user_id</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>full_text</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>in_reply_to_screen_name</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>user_mentions</th>\n",
              "      <th>url</th>\n",
              "      <th>image_url</th>\n",
              "      <th>name</th>\n",
              "      <th>party</th>\n",
              "      <th>legislative_period</th>\n",
              "      <th>lemmas</th>\n",
              "      <th>stems</th>\n",
              "      <th>pos_lemmas</th>\n",
              "      <th>pos_stems</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AlanTudgeMP</td>\n",
              "      <td>185932331</td>\n",
              "      <td>1.388275e+18</td>\n",
              "      <td>2021-04-30</td>\n",
              "      <td>Get the fundamentals right and lift our game. ...</td>\n",
              "      <td>18</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://www.theaustralian.com.au/inquirer/get-...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alan Tudge</td>\n",
              "      <td>Liberal Party of Australia</td>\n",
              "      <td>46</td>\n",
              "      <td>get fundamental right lift game see thought pr...</td>\n",
              "      <td>get fundament right lift game see thought prio...</td>\n",
              "      <td>lift game priority curriculum review</td>\n",
              "      <td>game nation curriculum review</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AlanTudgeMP</td>\n",
              "      <td>185932331</td>\n",
              "      <td>1.388274e+18</td>\n",
              "      <td>2021-04-30</td>\n",
              "      <td>RT @australian: State and federal education mi...</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>['australian']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alan Tudge</td>\n",
              "      <td>Liberal Party of Australia</td>\n",
              "      <td>46</td>\n",
              "      <td>state federal education minister set oppose el...</td>\n",
              "      <td>state feder educ minist set oppos element prop...</td>\n",
              "      <td>state education minister element school curric...</td>\n",
              "      <td>state feder minist element school curriculum b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AlanTudgeMP</td>\n",
              "      <td>185932331</td>\n",
              "      <td>1.388039e+18</td>\n",
              "      <td>2021-04-30</td>\n",
              "      <td>Great support for our $53m Higher Education su...</td>\n",
              "      <td>12</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://twitter.com/ITECAust/status/1387941814...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alan Tudge</td>\n",
              "      <td>Liberal Party of Australia</td>\n",
              "      <td>46</td>\n",
              "      <td>great support high education support package</td>\n",
              "      <td>great support higher educ support packag</td>\n",
              "      <td>support education support package</td>\n",
              "      <td>support support packag</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AlanTudgeMP</td>\n",
              "      <td>185932331</td>\n",
              "      <td>1.388035e+18</td>\n",
              "      <td>2021-04-30</td>\n",
              "      <td>RT @IndependentHEA: IHEA welcomes today’s anno...</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>['IndependentHEA', 'AlanTudgeMP', 'stuartrober...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alan Tudge</td>\n",
              "      <td>Liberal Party of Australia</td>\n",
              "      <td>46</td>\n",
              "      <td>ihea welcome todays announcement unveil suite ...</td>\n",
              "      <td>ihea welcom today announc unveil suit budget m...</td>\n",
              "      <td>welcome announcement suite budget measure …</td>\n",
              "      <td>ihea welcom today suit budget measur provid …</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AlanTudgeMP</td>\n",
              "      <td>185932331</td>\n",
              "      <td>1.388031e+18</td>\n",
              "      <td>2021-04-30</td>\n",
              "      <td>RT @ITECAust: The Australian — As @TimDoddEDU ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>['ITECAust', 'TimDoddEDU']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alan Tudge</td>\n",
              "      <td>Liberal Party of Australia</td>\n",
              "      <td>46</td>\n",
              "      <td>australian report iteca welcome australian gov...</td>\n",
              "      <td>australian report iteca welcom australian gove...</td>\n",
              "      <td>report government support …</td>\n",
              "      <td>report iteca welcom support provid …</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   screen_name    user_id      tweet_id created_at  \\\n",
              "0  AlanTudgeMP  185932331  1.388275e+18 2021-04-30   \n",
              "1  AlanTudgeMP  185932331  1.388274e+18 2021-04-30   \n",
              "2  AlanTudgeMP  185932331  1.388039e+18 2021-04-30   \n",
              "3  AlanTudgeMP  185932331  1.388035e+18 2021-04-30   \n",
              "4  AlanTudgeMP  185932331  1.388031e+18 2021-04-30   \n",
              "\n",
              "                                           full_text favorite_count  \\\n",
              "0  Get the fundamentals right and lift our game. ...             18   \n",
              "1  RT @australian: State and federal education mi...              0   \n",
              "2  Great support for our $53m Higher Education su...             12   \n",
              "3  RT @IndependentHEA: IHEA welcomes today’s anno...              0   \n",
              "4  RT @ITECAust: The Australian — As @TimDoddEDU ...              0   \n",
              "\n",
              "   retweet_count in_reply_to_screen_name hashtags  \\\n",
              "0            7.0                     NaN       []   \n",
              "1            6.0                     NaN       []   \n",
              "2            3.0                     NaN       []   \n",
              "3            2.0                     NaN       []   \n",
              "4            1.0                     NaN       []   \n",
              "\n",
              "                                       user_mentions  \\\n",
              "0                                                 []   \n",
              "1                                     ['australian']   \n",
              "2                                                 []   \n",
              "3  ['IndependentHEA', 'AlanTudgeMP', 'stuartrober...   \n",
              "4                         ['ITECAust', 'TimDoddEDU']   \n",
              "\n",
              "                                                 url  image_url        name  \\\n",
              "0  https://www.theaustralian.com.au/inquirer/get-...        NaN  Alan Tudge   \n",
              "1                                                NaN        NaN  Alan Tudge   \n",
              "2  https://twitter.com/ITECAust/status/1387941814...        NaN  Alan Tudge   \n",
              "3                                                NaN        NaN  Alan Tudge   \n",
              "4                                                NaN        NaN  Alan Tudge   \n",
              "\n",
              "                        party legislative_period  \\\n",
              "0  Liberal Party of Australia                 46   \n",
              "1  Liberal Party of Australia                 46   \n",
              "2  Liberal Party of Australia                 46   \n",
              "3  Liberal Party of Australia                 46   \n",
              "4  Liberal Party of Australia                 46   \n",
              "\n",
              "                                              lemmas  \\\n",
              "0  get fundamental right lift game see thought pr...   \n",
              "1  state federal education minister set oppose el...   \n",
              "2       great support high education support package   \n",
              "3  ihea welcome todays announcement unveil suite ...   \n",
              "4  australian report iteca welcome australian gov...   \n",
              "\n",
              "                                               stems  \\\n",
              "0  get fundament right lift game see thought prio...   \n",
              "1  state feder educ minist set oppos element prop...   \n",
              "2           great support higher educ support packag   \n",
              "3  ihea welcom today announc unveil suit budget m...   \n",
              "4  australian report iteca welcom australian gove...   \n",
              "\n",
              "                                          pos_lemmas  \\\n",
              "0               lift game priority curriculum review   \n",
              "1  state education minister element school curric...   \n",
              "2                  support education support package   \n",
              "3        welcome announcement suite budget measure …   \n",
              "4                        report government support …   \n",
              "\n",
              "                                           pos_stems  \n",
              "0                      game nation curriculum review  \n",
              "1  state feder minist element school curriculum b...  \n",
              "2                             support support packag  \n",
              "3      ihea welcom today suit budget measur provid …  \n",
              "4               report iteca welcom support provid …  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT50yqLvL0LH"
      },
      "source": [
        "final_df.to_csv(\"data/final_df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}