{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we use the output from the topic model and our immersion journal/manual to subset a training set of tweets about the Australian Bushfires. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing relevant packages\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm #to create a progress bar\n",
    "#Machine learning packages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Packages to create DFM\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#Packages for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#Word embeddings\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "#Gary King et. al key-words\n",
    "from keyword_algorithm import *\n",
    "#Remove unwarranted warnings\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Gary Kings semi-automated keyword retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/final_df.csv\", index_col=0)\n",
    "#Subset period June 2019 â€“ May 2020\n",
    "#data = data.loc[(data[\"created_at\"] >= \"2019-06-01\") & (data[\"created_at\"] <= \"2020-06-01\")]\n",
    "#data[\"id\"] = data.index\n",
    "data = data.dropna(subset = [\"lemmas\"]).reset_index(drop = True)\n",
    "data[\"index_col\"] = data.index\n",
    "#data.to_csv(\"data/query_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"data/wiki-news-300d-1M.vec\"\n",
    "fasttext = KeyedVectors.load_word2vec_format(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryBuilder:\n",
    "    \n",
    "    def __init__(self, emb_model):\n",
    "        \n",
    "        self.query = Keywords()\n",
    "        self.query.LoadDataset('data/query_df.csv', text_colname='lemmas', \n",
    "                               date_colname=\"created_at\", id_colname=\"index_col\")\n",
    "        self.we = emb_model\n",
    "        \n",
    "    def get_query(self, keywords):\n",
    "        \"\"\"\n",
    "        Loops over generated keywords\n",
    "        \"\"\"\n",
    "            \n",
    "            keepers = set()\n",
    "            \n",
    "            for keyword in keywords[\"accepted_keys\"]:\n",
    "                inp = input(f\"Should {keyword} go in ORs, ANDs\")\n",
    "                if inp == \"ORs\":\n",
    "                    keepers.add(keyword)\n",
    "                elif inp == \"ANDs\":\n",
    "                    for keyword2 in keywords[\"accepted_keys\"]:\n",
    "                        if keyword2 != keyword:\n",
    "                            inp2 = input(f\"keep ({keyword} AND {keyword2}), yes or no?\")\n",
    "                            if inp2 == \"yes\":\n",
    "                                keepers.add((f\"(?=.*{keyword})(?=.*{keyword2})\"))\n",
    "            \n",
    "                    for nokey in keywords[\"nontarget_keys\"]:\n",
    "                        inp3 = input(f\"keep ({keyword} AND NOT {nokey}), yes or no?\")\n",
    "                        if inp3 == \"yes\":\n",
    "                            keepers.add((f\"(^(?!.*{nokey})(?=.*{keyword})\"))\n",
    "            return keepers\n",
    "    \n",
    "    def get_keywords(self, its = 2, top_n = 10, refkeys = [], tarkeys = []):\n",
    "        \n",
    "        \n",
    "        accepted_keywords = []\n",
    "        rejected_keywords = []\n",
    "        nontarget_keywords = []\n",
    "        \n",
    "        #Begin loop for mining search set\n",
    "        for it in range(its):\n",
    "            print(\"-\"*66)\n",
    "            print(f\"STARTING ITERATION: {it}!\")\n",
    "            if it == 0:\n",
    "                print(\"INITIAL REFERENCE KEYS: {refkeys} \\n INITIAL TARGET KEYS: {tarkeys}\")\n",
    "            print(\"-\"*66)\n",
    "            \n",
    "            #Build reference set of tweets\n",
    "            self.query.ReferenceSet(any_words=refkeys, date_start=\"2019-06-01\", date_end=\"2020-05-30\")\n",
    "            if it > 0:\n",
    "                #fit model on searchset and find target\n",
    "                self.query.SearchSet(any_words= accepted_keywords, date_start=\"2019-06-01\", date_end=\"2020-05-30\")\n",
    "            else:\n",
    "                self.query.SearchSet(any_words = tarkeys, date_start=\"2019-06-01\", date_end=\"2020-05-30\")\n",
    "            \n",
    "            self.query.ProcessData(stem = False, keep_twitter_symbols=False,\n",
    "                                   remove_wordlist=refkeys)\n",
    "            self.query.ReferenceKeywords()\n",
    "            self.query.ClassifyDocs(min_df=10, ref_trainprop=1, algorithms=['nbayes', 'logit'])\n",
    "            self.query.FindTargetSet()\n",
    "            self.query.FindKeywords()\n",
    "            #Extract target keywords from model\n",
    "            target_keywords = self.query.target_keywords[:top_n]\n",
    "            #Also get the reference set keywords\n",
    "            target_keywords += self.query.reference_keywords[:top_n]\n",
    "            for nonkey in self.query.nontarget_keywords[:100]:\n",
    "                if nonkey not in nontarget_keywords:\n",
    "                    nontarget_keywords.append(nonkey)\n",
    "            \n",
    "            for keyword in target_keywords:\n",
    "                if keyword in accepted_keywords or keyword in rejected_keywords:\n",
    "                    continue\n",
    "                else:\n",
    "                    inp = input(f\"Keep {keyword.upper()} yes or no?\")\n",
    "                    if inp == \"yes\":\n",
    "                        accepted_keywords.append(keyword)\n",
    "                \n",
    "                        #get similar keywords through most similar pretrained embeddings\n",
    "                        inp2 = input(f\"Look at {keyword.upper()}'s most similar word embeddings, yes or no?\")\n",
    "                        if inp2 == \"yes\":\n",
    "                            try:\n",
    "                                embeddings = [emb[0] for emb in self.we.most_similar(keyword)]\n",
    "                                for emb in embeddings:\n",
    "                                    if emb.lower() in accepted_keywords or emb.lower() in rejected_keywords:\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        inp3 = input(f\"Keep embedding {emb.upper()} yes or no?\")\n",
    "                                        if inp3 == \"yes\":\n",
    "                                            accepted_keywords.append(emb)\n",
    "                                        elif inp3 ==\"no\":\n",
    "                                            rejected_keywords.append(emb)\n",
    "                            except:\n",
    "                                print(f\"{keyword.upper()} embedding not present in Model!\")\n",
    "                                pass\n",
    "                        elif inp2 == \"no\":\n",
    "                            pass\n",
    "                    elif inp == \"no\":\n",
    "                        rejected_keywords.append(keyword)\n",
    "                        \n",
    "            #Add custom keyword(s)\n",
    "            inp4 = input(f\"Do you wish to add any further keywords? If yes, Type keyword: \")\n",
    "            if inp4:\n",
    "                if isinstance(inp4, list):\n",
    "                    [accepted_keywords.append(key) for key in inp4]\n",
    "                else:\n",
    "                     accepted_keywords.append(inp4)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            print(\"-\"*66)\n",
    "            print(\" \"*20, f\"CURRENT KEYWORDS AFTER ITTERATION {it}\")\n",
    "            print(\"-\"*66)\n",
    "            print(f\"ACCEPTED: \\n {accepted_keywords}\")\n",
    "            print(f\"REJECTED: \\n {rejected_keywords}\")\n",
    "            \n",
    "        \n",
    "        keywords = {\"accepted_keys\":accepted_keywords, \"rejected_keys\":rejected_keywords,\"nontarget_keys\":nontarget_keywords}\n",
    "        \n",
    "        return keywords\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword object initialized.\n",
      "Loaded corpus of size 148540 in 3.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "query = QueryBuilder(fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = query.get_keywords(2, top_n=10, refkeys=[\"#bushfire\", \"#bushfires\", \"bushfire\", \"bushfires\"], tarkeys = [\"fire\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"|\".join(keywords[\"accepted_keys\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the key-words from Kings model to subset tweets. Next we use this subset to predict the party of the tweet and analyze the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlogitMargins:\n",
    "    \"\"\"\n",
    "    Calculates marginal effect of multinomial logit coefficients with bootstraped confidence interval.\n",
    "    See https://github.com/alicehwu/gendered_language/blob/master/gendered_language_2018.pdf for a \n",
    "    reference on a similar approach but with binary classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        #Define data\n",
    "        self.vect = CountVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "        self.X = self.vect.fit_transform(X)\n",
    "        self.y = y\n",
    "        print(\"Fitting model and calculating margins...\")\n",
    "        #Fit model and calculate average marginal effects\n",
    "        self.margins, self.fitted_model = self.avg_margins(self.X, self.y)\n",
    "\n",
    "    def bootstrap_ci(self, alpha = 0.05, n_samples = 500, sample_prop = 0.4):\n",
    "        \"\"\"\n",
    "        Uses bootstraping to calculate confidence interval around average marginal effects estimate.\n",
    "        -------------\n",
    "        Arguments:\n",
    "            - alpha: deterimines confidence level of the interval\n",
    "            - n_samples: amount of bootstrap samples\n",
    "            - sample_prop: bootstramp sample size as proportion of original sample\n",
    "        -------------\n",
    "        Return:\n",
    "            - Pandas dataframe with confidence interval for average marginal effect\n",
    "              of each coefficient.\n",
    "        \"\"\"\n",
    "        statistics = [] #List for bootstrap results\n",
    "        \n",
    "        #Define the bootstrap sample size based on proportion of total\n",
    "        n_size = int(self.X.shape[0] * sample_prop)\n",
    "        print(f\"Number of obs in bootstrap samples {n_size}...\")\n",
    "        for i in tqdm(range(n_samples)):\n",
    "\n",
    "            #Draw random sample from X and y with replacement\n",
    "            idx = np.random.choice(np.arange(self.X.shape[0]), n_size, replace=True)\n",
    "            X_sample = self.X[idx]\n",
    "            y_sample = self.y[idx]\n",
    "            #Calculate marginal effect for sample\n",
    "            margins = self.avg_margins(X_sample, y_sample)[0]\n",
    "            statistics.append(margins)\n",
    "        \n",
    "        #Join the resulting dataframes of margins\n",
    "        statistics = pd.concat(statistics)\n",
    "        print(f\"Boostraping Done. Calculating {1-alpha}% confidence interval...\")\n",
    "        start = time.time()\n",
    "        #From bootstrap results get lower and upper CI limits based on alpha\n",
    "        statistics = statistics.groupby(\"token\").quantile([alpha, 1-alpha]).reset_index()        \n",
    "        print(\"Time to calculate: \", time.time() - start)\n",
    "\n",
    "        return statistics\n",
    "        \n",
    "\n",
    "    def fit_model(self, X, y, max_iter = 10000, penalty = \"none\", class_weight = \"balanced\",\n",
    "                  verbose = False, fit_intercept = True, multi_class = \"multinomial\"):\n",
    "        \n",
    "        \"\"\"\n",
    "        Fits sklearn multinomial logistic model on data. Default penalty set to \"none\" for unbaised estimators.\n",
    "        \"\"\"\n",
    "\n",
    "        mlogit = LogisticRegression(random_state=42, penalty=penalty, solver=\"saga\", \n",
    "                                    max_iter = max_iter, class_weight = class_weight,\n",
    "                                    fit_intercept=fit_intercept, multi_class=\"ovr\",\n",
    "                                    verbose=verbose).fit(X, y) #   \n",
    "\n",
    "        return mlogit\n",
    "\n",
    "    def avg_margins(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculates average marginal effect of coefficients in multinomial logit model, where each coefficient is \n",
    "        a word token and is calculated as:\n",
    "        avg_margin_jk = beta_jk * 1/N * sum{P(y_i = J) * 1-P(y_i = J)} for each token k and class j.\n",
    "        See: https://math.stackexchange.com/questions/863258/deriving-marginal-effects-in-multinomial-logit-model\n",
    "        \n",
    "        \"\"\"\n",
    "        #Fit the model\n",
    "        model = self.fit_model(X, y)\n",
    "        #Get probabilities for each obs i belonging to class j. shape = j * N\n",
    "        probas = model.predict_proba(X)\n",
    "        #Get coefficients. Shape j_classes * k_coefficients\n",
    "        betas = model.coef_\n",
    "\n",
    "        margins = {}\n",
    "        #Loop over each class \n",
    "        for class_j in range(len(model.classes_)):\n",
    "            #Extract corresponging betas. shape 1*k\n",
    "            for beta_jk in betas[class_j]:\n",
    "                \n",
    "                #Calculate avg margins for the jth class and kth beta (token)\n",
    "                margins_jk = beta_jk * 1/probas.shape[0] * (probas[:,class_j] * (1 - probas[:,class_j])).sum()\n",
    "                \n",
    "                #Append avg margins to dictionary\n",
    "                if model.classes_[class_j] not in margins.keys():\n",
    "                    margins[model.classes_[class_j]] = [margins_jk]\n",
    "                else:\n",
    "                    margins[model.classes_[class_j]].append(margins_jk)\n",
    "        \n",
    "        #Extract the token name corresponding to the avg margins   \n",
    "        margins[\"token\"] = self.vect.get_feature_names()\n",
    "        margins_df = pd.DataFrame(margins)\n",
    "        \n",
    "        return margins_df, model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = \"|\".join(keywords[\"accepted_keys\"])\n",
    "#Extract most predictive keywords from model\n",
    "mlogit_data = data.loc[(data[\"lemmas\"].str.contains(\"bushfire|bushfires|#bushfire|#bushfires|disaster|kaoala|fire|flames|firemen\") == True) & \n",
    "                       (data[\"lemmas\"].str.contains(\"corona|covid\") == False) & \n",
    "                       (data[\"created_at\"] >= \"2019-06-01\") & \n",
    "                       (data[\"created_at\"] <= \"2020-06-01\")]\n",
    "\n",
    "mlogit_data = mlogit_data.loc[mlogit_data[\"party\"].isin([\"Australian Greens\",\n",
    "                                                         \"Australian Labor Party\", \n",
    "                                                         \"Liberal Party of Australia\",\n",
    "                                                          ])].dropna(subset = [\"lemmas\"]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model and calculating margins...\n"
     ]
    }
   ],
   "source": [
    "X, y = mlogit_data[\"lemmas\"], mlogit_data[\"party\"]\n",
    "mlogit = MlogitMargins(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Australian Greens</th>\n",
       "      <th>Australian Labor Party</th>\n",
       "      <th>Liberal Party of Australia</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3158</th>\n",
       "      <td>-0.002530</td>\n",
       "      <td>-0.014292</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>-0.006856</td>\n",
       "      <td>-0.010107</td>\n",
       "      <td>0.004438</td>\n",
       "      <td>auspol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>-0.002164</td>\n",
       "      <td>-0.011049</td>\n",
       "      <td>0.004235</td>\n",
       "      <td>ensure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6022</th>\n",
       "      <td>-0.000277</td>\n",
       "      <td>-0.010020</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>pm scottmorri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>-0.001525</td>\n",
       "      <td>-0.009901</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-0.001331</td>\n",
       "      <td>-0.009350</td>\n",
       "      <td>0.003582</td>\n",
       "      <td>courage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>-0.000395</td>\n",
       "      <td>-0.010631</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>defence force</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-0.001000</td>\n",
       "      <td>-0.009579</td>\n",
       "      <td>0.003561</td>\n",
       "      <td>additional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4490</th>\n",
       "      <td>-0.001865</td>\n",
       "      <td>-0.008943</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6322</th>\n",
       "      <td>-0.000740</td>\n",
       "      <td>-0.009200</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>present special</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6321</th>\n",
       "      <td>-0.000740</td>\n",
       "      <td>-0.009200</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5539</th>\n",
       "      <td>0.001535</td>\n",
       "      <td>-0.011075</td>\n",
       "      <td>0.003349</td>\n",
       "      <td>payment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7895</th>\n",
       "      <td>0.001076</td>\n",
       "      <td>-0.012599</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>terrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3052</th>\n",
       "      <td>-0.000874</td>\n",
       "      <td>-0.009289</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>-0.002527</td>\n",
       "      <td>-0.007278</td>\n",
       "      <td>0.003148</td>\n",
       "      <td>centre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Australian Greens  Australian Labor Party  Liberal Party of Australia  \\\n",
       "3158          -0.002530               -0.014292                    0.005408   \n",
       "367           -0.006856               -0.010107                    0.004438   \n",
       "1897          -0.002164               -0.011049                    0.004235   \n",
       "6022          -0.000277               -0.010020                    0.004034   \n",
       "924           -0.001525               -0.009901                    0.003847   \n",
       "1371          -0.001331               -0.009350                    0.003582   \n",
       "1542          -0.000395               -0.010631                    0.003562   \n",
       "64            -0.001000               -0.009579                    0.003561   \n",
       "4490          -0.001865               -0.008943                    0.003500   \n",
       "6322          -0.000740               -0.009200                    0.003465   \n",
       "6321          -0.000740               -0.009200                    0.003465   \n",
       "5539           0.001535               -0.011075                    0.003349   \n",
       "7895           0.001076               -0.012599                    0.003241   \n",
       "3052          -0.000874               -0.009289                    0.003216   \n",
       "992           -0.002527               -0.007278                    0.003148   \n",
       "\n",
       "                token  \n",
       "3158             join  \n",
       "367            auspol  \n",
       "1897           ensure  \n",
       "6022    pm scottmorri  \n",
       "924            canada  \n",
       "1371          courage  \n",
       "1542    defence force  \n",
       "64         additional  \n",
       "4490          network  \n",
       "6322  present special  \n",
       "6321          present  \n",
       "5539          payment  \n",
       "7895         terrible  \n",
       "3052          initial  \n",
       "992            centre  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlogit.margins.sort_values(\"Liberal Party of Australia\", ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of obs in bootstrap samples 880...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [01:10<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boostraping Done. Calculating 0.95% confidence interval...\n",
      "Time to calculate:  0.403839111328125\n"
     ]
    }
   ],
   "source": [
    "mlogit_ci = mlogit.bootstrap_ci(alpha=0.05, n_samples=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>level_1</th>\n",
       "      <th>Australian Greens</th>\n",
       "      <th>Australian Labor Party</th>\n",
       "      <th>Liberal Party of Australia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandon</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.000637</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.001071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandon</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>-0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandon morrison</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandon morrison</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abate</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abate</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abate community</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abate community</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abc</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.000932</td>\n",
       "      <td>-0.000534</td>\n",
       "      <td>-0.001135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abc</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              token  level_1  Australian Greens  Australian Labor Party  \\\n",
       "0           abandon     0.05          -0.000637                0.000031   \n",
       "1           abandon     0.95          -0.000007                0.001977   \n",
       "2  abandon morrison     0.05          -0.000022                0.000000   \n",
       "3  abandon morrison     0.95           0.000000                0.000866   \n",
       "4             abate     0.05          -0.000114                0.000000   \n",
       "5             abate     0.95           0.000000                0.000387   \n",
       "6   abate community     0.05          -0.000114                0.000000   \n",
       "7   abate community     0.95           0.000000                0.000387   \n",
       "8               abc     0.05          -0.000932               -0.000534   \n",
       "9               abc     0.95          -0.000061                0.002493   \n",
       "\n",
       "   Liberal Party of Australia  \n",
       "0                   -0.001071  \n",
       "1                   -0.000017  \n",
       "2                   -0.000259  \n",
       "3                    0.000000  \n",
       "4                   -0.000150  \n",
       "5                    0.000000  \n",
       "6                   -0.000150  \n",
       "7                    0.000000  \n",
       "8                   -0.001135  \n",
       "9                    0.000369  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlogit_ci.head(10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdd379f7bb8e06f7ec29e5b7f14bfd985640a300b5a41de1996cc2754af32f7b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
